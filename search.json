[
  {
    "objectID": "posts/2020-09-09-google-mobility-trends/mobility-trends.html",
    "href": "posts/2020-09-09-google-mobility-trends/mobility-trends.html",
    "title": "Mobilitetstrender från Apple och Google",
    "section": "",
    "text": "Under 2020 har det släppts flera nya R-paket som fokuserar på Covid19. Bland annat har ett initiativ av John Hopkins University tagits fram där man försökt standardisera många av de datakällor som finns för covid-relaterad data.\nEtt av dessa är Apple respektive Google’s mobilitetsdata som de båda techgiganterna släppte öppet i våras.\nData finns (bland annat) i paketet covmobility. Apple har släppt data som baseras på antalet förfrågningar för vägbeskrivningar för respektive färdmedel. Det är inte lika tydligt hur Google beräknar sin mobilitet men antagligen baseras den mer på platsdata då Google’s data dels täcker rörelse i parker, besök i mataffärer m.m.\nVi kan ladda ner paketen vi behöver:\n\nremotes::install_github(\"kjhealy/covmobility\")\ninstall.packages(\"tidyverse\")\n\nPaketet är enkelt att använda. Här laddar vi in data, filtrerar ut Sverige och visualiserar:\n\nlibrary(covmobility)\nlibrary(tidyverse)\n\ndata(apple_mobility)\n\napple_mobility %>% \n  filter(region == \"Sweden\" & date < '2020-09-09') %>% \n  ggplot(aes(x = date, y = score, color = transportation_type)) +\n  geom_line() +\n  scale_x_date(breaks = scales::pretty_breaks(12)) +\n  theme_minimal() +\n  scale_color_viridis_d() +\n  labs(\n    title = \"Mobilitetstrend\",\n    subtitle = \"Apple's index för mobilitet: mäts genom antal förfrågningar på vägbeskrivningar.\",\n    caption = \"Källa: Apple \",\n    x = \"\",\n    y = \"Index\",\n    color = \"\"\n  )\n\n\n\n\nVi kan jämföra länder mot varandra.\n\napple_mobility %>% \n  filter(region %in% c(\"Sweden\", \"Finland\", \"Norway\", \"Denmark\") & date < '2020-09-09') %>% \n  ggplot(aes(x = date, y = score, color = region)) +\n  geom_line() +\n  scale_x_date(breaks = scales::pretty_breaks(12)) +\n  theme_minimal() +\n  scale_color_viridis_d() +\n  labs(\n    title = \"Mobilitetstrend\",\n    subtitle = \"Apple's index för mobilitet: mäts genom antal förfrågningar på vägbeskrivningar.\",\n    caption = \"Källa: Apple\",\n    x = \"\",\n    y = \"Index\",\n    color = \"\"\n  ) +\n    facet_grid(rows = vars(transportation_type), scales = \"free\")\n\n\n\n\nDu kan undersöka data mer på Githubsidan för covmobility: https://github.com/kjhealy/covmobility/"
  },
  {
    "objectID": "posts/2023-02-07-python-envs/python-envs.html",
    "href": "posts/2023-02-07-python-envs/python-envs.html",
    "title": "My setup for virtual environments in Python",
    "section": "",
    "text": "At least once a year I get a chance to dable with Python. This time I’m involved in a project where we have developed outlier detection algorithms for district heating networks. To run the Python code and the application built on top of it I have to use a specific version of Python and some specific package versions.\nSo I started up my Python environment. Eager to get started. But instead of investigating the code and the results from the algorithm I got stuck on installing the correct package versions.\nI have been down this road before. Usually it means I have to spend a day googling and following different tutorials to get everything to work. But I have never really understood why. So I thought I would do this a bit more thorough and write everything down this time."
  },
  {
    "objectID": "posts/2023-02-07-python-envs/python-envs.html#why-write-this-post",
    "href": "posts/2023-02-07-python-envs/python-envs.html#why-write-this-post",
    "title": "My setup for virtual environments in Python",
    "section": "Why write this post",
    "text": "Why write this post\nI primarily use R to analyze data. After working out package management in Python I have realized that R users are very spoiled by the package management system that is built into R. When I install a package via install.packages(\"packagename\") it just works. This is very nice feature since most of my work is experimental. I mainly use R to investigate something: manipulate, visualize and model data. This means that the less time I need to spend on setup, the more productive I can be."
  },
  {
    "objectID": "posts/2023-02-07-python-envs/python-envs.html#virtual-environments-are-not-new-to-me",
    "href": "posts/2023-02-07-python-envs/python-envs.html#virtual-environments-are-not-new-to-me",
    "title": "My setup for virtual environments in Python",
    "section": "Virtual environments are not new to me",
    "text": "Virtual environments are not new to me\nOf course, if I want my code to be used for production, for example scheduling a script, I want to make sure that the script doesn’t fail if I change my setup, like updating a package. So I’m familiar with the concept of virtual environments. I have used R packages for this, like renv and packrat, and also Docker. But I use these when I need them."
  },
  {
    "objectID": "posts/2023-02-07-python-envs/python-envs.html#virtual-environments-in-python",
    "href": "posts/2023-02-07-python-envs/python-envs.html#virtual-environments-in-python",
    "title": "My setup for virtual environments in Python",
    "section": "Virtual environments in Python",
    "text": "Virtual environments in Python\nIn order to use Python productivly most developers will encourage you to use Virtual Environments. If you are a Data Scientist that uses a bundled Python distribution like Anaconda, you might be using a virtual environment without thinking to much about it.\nPeople use Virtual Environments to isolate projects from each other. In other words, the packages you use in one project can be different (versions) from another project, and when you open up a separate project it should’nt be dependent on the virtual environment in another project. I think of virtual environments as folders where you save all the packages that you use for a project in Python."
  },
  {
    "objectID": "posts/2023-02-07-python-envs/python-envs.html#venv",
    "href": "posts/2023-02-07-python-envs/python-envs.html#venv",
    "title": "My setup for virtual environments in Python",
    "section": "venv",
    "text": "venv\nThe most basic way to create virtual environment in Python is venv.\nTo use it is pretty straight forward:\n\npython3 -m venv path-to-mynewenv\n\nThis create a folder in your directory where the packages installed for your virtual environment will be saved.\n\nWhat version are we using?\nWhen you open the terminal and type python --version you can get different answers. I found this article really helpful in understanding why this happens. This effects our virtual environment as venv will inherit your Python version. As it says in the Python documentation:\n\n\nA virtual environment is created on top of an existing Python installation, known as the virtual environment’s “base”\n\n\nIn other words: we cannot specify Python version for virtual environments with venv. To do that you will have to use something like pyenv.\nAnyways, to use the environment we created we need to activate it:\n\nsource mynewenv/bin/activate\n\nand then we can then install packages into it:\n\npip install pandas numpy\n\nThis works. But I usually want to use a virtual environment in many different projets and not have to install everything again when doing a new projet. Also, I want to have control of the version of Python that I’m using."
  },
  {
    "objectID": "posts/2023-02-07-python-envs/python-envs.html#anaconda-and-conda",
    "href": "posts/2023-02-07-python-envs/python-envs.html#anaconda-and-conda",
    "title": "My setup for virtual environments in Python",
    "section": "Anaconda and conda",
    "text": "Anaconda and conda\nA popular distribution and platform for working with Python is Anaconda. Anaconda is not only for Python. On its website it says:\n\n\nPackage, dependency and environment management for any language—Python, R, Ruby, Lua, Scala, Java, JavaScript, C/ C++, FORTRAN\n\n\nIn other words, when you install Anaconda, you install a lot.\n\nconda\nconda is the package manager built into Anaconda. For Python you use it the same way as venv but instead of creating a virtual environment for each project you can use conda to create environments that you can use over many projects.\n\n\nIt should be noted that I installed Anaconda and conda a long time ago so I had to update it before getting it to work properly. First run: conda update conda, then conda install anaconda, not sure why and lastly I had to run conda update --all to get it to work the way I wanted. This took a while.\n\n\nBut as soon as it worked I was able to create an environment where I also can specify the python version.\n\nconda create -n pythonds python=3.8\n\nTo install packages into the conda environment you run: conda install -n condaenv numpy=1.19.2 pandas=1.2.3\nI wanted to use the environment in a Quarto document. To do this I also had to register it to the ipykernel.\n\npython -m ipykernel install --user --name=pythonds"
  },
  {
    "objectID": "posts/2023-02-07-python-envs/python-envs.html#the-setup-that-now-works-for-me",
    "href": "posts/2023-02-07-python-envs/python-envs.html#the-setup-that-now-works-for-me",
    "title": "My setup for virtual environments in Python",
    "section": "The setup that now works for me",
    "text": "The setup that now works for me\nAt some point we just want things to work. And right now this is what works for me when working with Python.\n\nI create and manage virtual environments with conda\nIf I want to share my virtual environment I create a conda.yml file which is the equivalent of a requirements.txt file to specify dependencies\nLastly, because I use Quarto, I have to register the environment to the jupyter kernel\n\nThis setup works for me right now. Crossing my fingers that it will work tomorrow."
  },
  {
    "objectID": "posts/2023-02-07-python-envs/python-envs.html#bonus-tricks",
    "href": "posts/2023-02-07-python-envs/python-envs.html#bonus-tricks",
    "title": "My setup for virtual environments in Python",
    "section": "Bonus tricks",
    "text": "Bonus tricks\n\nminiconda\nAs I mentioned conda is not restricted to Python. A smaller version of conda, primarily made for Python is miniconda:\n\n\nMiniconda is a free minimal installer for conda. It is a small, bootstrap version of Anaconda that includes only conda, Python, the packages they depend on, and a small number of other useful packages, including pip, zlib and a few others. Use the conda install command to install 720+ additional conda packages from the Anaconda repository.”\n\n\nThe good thing about Miniconda is that you can use conda in the same way. So to create a virtual environment you do exactly the same: conda create -n minienv python=3.8. If I would start again I would probably restrict myself ot miniconda but I haven’t really figured out how to run these things separate.\n\n\npyenv\nWith conda you can specify Python version, but not with venv. If you want to switch Python versions most people will suggest pyenv. You can use pyenv in a similar fashion to venv."
  },
  {
    "objectID": "posts/2023-03-03-python-and-quarto/python-and-quarto.html",
    "href": "posts/2023-03-03-python-and-quarto/python-and-quarto.html",
    "title": "Python in Quarto",
    "section": "",
    "text": "I always have trouble with Python environments. To be honest I haven’t really found a setup that I like for it.\nNevertheless, I want to try out some Python in Quarto. So here is a short note on how I went about using conda to do that.\nI already had a Python environment that I wanted to use. In the quarto yaml, i.e. the header you can specify the Jupyter kernel you would like to use.\nFor this post it looks like this:\n---\ntitle: \"Python in Quarto\"\nauthor: \"Filip Wästberg\"\ndate: \"2023-03-03\"\ncategories: [python]\njupyter: pyds\nimage: minions.png\n---\nSo I had created an environment based on a conda.yaml file like this:\nconda env create -f conda_env.yml\nAnd activate it\nconda activate pyds \nThe actual yaml file looked like this:\nname: pyds\nchannels:\n  - https://repo.anaconda.com/pkgs/snowflake\n  - nodefaults\ndependencies:\n  - python=3.8\n  - pip\n  - pip:\n    # Snowpark\n    - snowflake-snowpark-python[pandas]==0.10.0\n    # Basics\n    - pandas==1.4.3\n    - numpy==1.22.3\n    # ML\n    - scikit-learn==1.1.1\n    - lightgbm==3.2.1\n    - xgboost==1.5.0\n    # Visualization\n    ...\nHowever, to be able to use this environment in Quarto I have to register it to jupyter.\nI did that like this:\npython -m ipykernel install --user --name=pyds"
  },
  {
    "objectID": "posts/2020-08-17-databaser-i-r/databaser-i-r.html",
    "href": "posts/2020-08-17-databaser-i-r/databaser-i-r.html",
    "title": "Databser i R",
    "section": "",
    "text": "Att jobba med databaser är en av de viktigaste uppgifterna en analytiker eller data scientist har. En tillräckligt stor organisation kan ha flera databaser med olika information och ibland med samma (om än inte alltid överensstämmande). Många databaser som är skräddarsydda för en organisation har egna User Interface (UI) av varierande kvalitet. Det här leder ibland till att analytiker och data scientists lägger ner mycket tid på att hoppa mellan olika UI:s för olika databaser. Det sägs ibland att en Data Scientist arbetar till 80% med databearbetning, men om personen i fråga spenderar dagarna att navigera olika databaser och deras UI:s är den siffran säkert högre.\nAtt nå och effektivit kunna kommunicera med databaser från ett och samma verktyg kan spara en Data Scientist mycket tid."
  },
  {
    "objectID": "posts/2020-08-17-databaser-i-r/databaser-i-r.html#databaser-i-r",
    "href": "posts/2020-08-17-databaser-i-r/databaser-i-r.html#databaser-i-r",
    "title": "Databser i R",
    "section": "Databaser i R",
    "text": "Databaser i R\nDet finns flera sätt att göra det här på, men jag kommer att argumentera för att göra det i R och IDE:n RStudio.\nR har gjort en osannolik resa från att vara ett ganska nischat programmeringsspråk för statistiker till att bli ett av det mest populära verktygen att göra dataanalys i. Ett viktigt skäl till R:s framgång är paketet dplyr. dplyr används för att göra datamanipulering och bearbetning enklare, med ett starkt fokus på läsbarhet och användarvänlighet. Det har ett intuitivt syntax som i princip vem som helst kan förstå.\nFör att visa hur enkelt dplyr:s syntax är kan vi utgå från data om irisblomman. Nedan filterar vi först bort arten “setosa” och räknar sedan ut den genomsnittliga bladlängden per art. I princip vem som helst kan förstå ungefär vad som pågår nedan.\n\nlibrary(dplyr)\niris %>% \n  filter(Species != \"setosa\") %>% \n  group_by(Species) %>% \n  summarise(mean_sepal_length = mean(Sepal.Length))\n\n# A tibble: 2 × 2\n  Species    mean_sepal_length\n  <fct>                  <dbl>\n1 versicolor              5.94\n2 virginica               6.59\n\n\nVad har det här med databaser att göra? Eftersom data i arbetslivet ofta ligger i databaser har utvecklarna bakom dplyr lagt ner mycket tid på att skriva SQL-översättningar från dplyr till olika databaser. Vad det här innebär i praktiken är att du kan använda dplyr-syntax för att göra komputeringar i en databas.\nLåt oss göra exakt det här genom att skapa en exempeldatabas. Generellt behöver vi användarnamn, lösenord och serverspecifikation för att ansluta till en databas. Men principerna är desamma oavsett om vi skapar den tillfälligt på datorn eller om det är en livs levande databas. För att arbeta med databaser i R laddar vi också paketen DBI och dbplyr.\n\nlibrary(DBI)\nlibrary(dbplyr)\n\ncon <- dbConnect(RSQLite::SQLite(), \":memory:\")\n\ndbWriteTable(con, \"iris\", iris)\n\niris_tbl <- tbl(con, \"iris\")\n\nObjektet iris_tbl är nu en koppling till tabellen iris i databasen con. Vi kan också titta igenom våra databasobjekt under Connections i RStudio.\n\nNär vi nu har en databas kan vi använda dplyr för att bearbeta data i databasen.\n\niris_tbl %>% \n  group_by(Species) %>% \n  summarise(mean_sepal_length = mean(Sepal.Length))\n\nWarning: Missing values are always removed in SQL.\nUse `mean(x, na.rm = TRUE)` to silence this warning\nThis warning is displayed only once per session.\n\n\n# Source:   lazy query [?? x 2]\n# Database: sqlite 3.39.3 [:memory:]\n  Species    mean_sepal_length\n  <chr>                  <dbl>\n1 setosa                  5.01\n2 versicolor              5.94\n3 virginica               6.59\n\n\nOvan kod exekveras alltså inte i R, som generellt körs lokalt på en server eller en dator, utan på den server där databasen ligger. I bakgrunden översätter dplyr koden till SQL. Vi kan se hur den översatta queryn ser ut genom show_query():\n\niris_tbl %>% \n  group_by(Species) %>% \n  summarise(mean_sepal_length = mean(Sepal.Length)) %>% \n  show_query()\n\n<SQL>\nSELECT `Species`, AVG(`Sepal.Length`) AS `mean_sepal_length`\nFROM `iris`\nGROUP BY `Species`\n\n\nPoängen är att vi kan använda R för att exekvera databearbetningar på mycket större datamängder i en databas än vad som är möjligt direkt i R.\nNär vi är klara med, säg en aggregering, kan vi enkelt ta in resultatet till R och modellera eller visualisera resultatet.\n\nlibrary(ggplot2)\niris_tbl %>% \n  group_by(Species) %>% \n  summarise(mean_sepal_length = mean(Sepal.Length)) %>% \n  collect() %>% \n  ggplot() +\n  aes(y = Species, x = mean_sepal_length, fill = Species) +\n  geom_col() +\n  theme(legend.position = \"none\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/2020-08-17-databaser-i-r/databaser-i-r.html#vad-innebär-det-här-för-en-analytiker",
    "href": "posts/2020-08-17-databaser-i-r/databaser-i-r.html#vad-innebär-det-här-för-en-analytiker",
    "title": "Databser i R",
    "section": "Vad innebär det här för en analytiker?",
    "text": "Vad innebär det här för en analytiker?\nDet här gör att vi som analytiker kan arbeta sömlöst med databaser direkt i R. Vi slipper hoppa mellan olika UI:s för alla de databaser som finns i vår organisation. Vi kan aggregera och manipulera data via databasen och sedan lyfta in det i R för att där skapa statistiska modeller och AI-flöden och på så sätt demokratisera\nFör en analytiker är själva databearbetningen bara ett steg i analysen och om man kan flytta databearbetningen närmare ett analytiskt verktyg, som R, kan man dels spara tid men framför allt bygga mer robusta flöden.\n/ Filip"
  },
  {
    "objectID": "posts/2020-08-14-kolada/anropa-kolada-R.html",
    "href": "posts/2020-08-14-kolada/anropa-kolada-R.html",
    "title": "Hämta data från Kolada till R",
    "section": "",
    "text": "I ett tidigare inlägg tittade jag på hur man kan hämta data direkt från SCB till R med hjälp av paketet pxweb.\nSCB har massa intressant data men mycket är på en nationell nivå. En annan datakälla, som är helt inriktad på kommunal och regional statistik, är Kolada, som är Sveriges kommuner och regioners (SKR) webbtjänst för regional statistik.\nLikt SCB har Kolada ett gränssnitt på webben, och precis som SCB har de också ett öppet API. Love Hansson, som är analytiker på Pensionsmyndigheten, har byggt ett paket för att anropa Kolada från R. Det här innebär att om du jobbar mycket med kommunal eller regional statistik kan du med hjälp av R-skript automatisera all inhämtning och rapportering av regional statistik från Kolada."
  },
  {
    "objectID": "posts/2020-08-14-kolada/anropa-kolada-R.html#rkolada",
    "href": "posts/2020-08-14-kolada/anropa-kolada-R.html#rkolada",
    "title": "Hämta data från Kolada till R",
    "section": "rKolada",
    "text": "rKolada\nPaketet installeras enkelt med install.packages(\"rKolada\").\nFör att få en övergripande bild över Koladas datamodell och paketet rKolada kan jag varmt rekommendera Love Hanssons vignette som finns här."
  },
  {
    "objectID": "posts/2020-08-14-kolada/anropa-kolada-R.html#hur-kolada-fungerar",
    "href": "posts/2020-08-14-kolada/anropa-kolada-R.html#hur-kolada-fungerar",
    "title": "Hämta data från Kolada till R",
    "section": "Hur Kolada fungerar",
    "text": "Hur Kolada fungerar\nPå Koladas hemsida kan du enkelt söka efter olika KPI-er. Där kan du också få en enkel tabell och visualisering av resultatet. rKolada ger oss möjlighet att programmatiskt ta ut dessa tabeller, vilket underlättar om vi behöver ta ut statistik fler gånger än en.\nMed funktionen get_kpi() får vi en tabell med alla KPI-er som finns tillgängliga.\n\nlibrary(rKolada)\nlibrary(tidyverse)\n\nkpis <- get_kpi()\n\nkpis\n\n# A tibble: 5,522 × 13\n   auspices description      has_ou_data id    is_divided_by_g… municipality_ty…\n   <chr>    <chr>            <lgl>       <chr>            <int> <chr>           \n 1 E        Personalkostnad… NA          N000…                0 K               \n 2 E        Personalkostnad… FALSE       N000…                0 K               \n 3 X        Kommunalekonomi… FALSE       N000…                0 K               \n 4 <NA>     Externa intäkte… FALSE       N000…                0 K               \n 5 <NA>     Inkomstutjämnin… FALSE       N000…                0 K               \n 6 <NA>     Kostnadsutjämni… FALSE       N000…                0 K               \n 7 X        Regleringsbidra… FALSE       N000…                0 K               \n 8 <NA>     Utjämningssyste… FALSE       N000…                0 K               \n 9 X        Införandebidrag… FALSE       N000…                0 K               \n10 X        Strukturbidrag,… FALSE       N000…                0 K               \n# … with 5,512 more rows, and 7 more variables: operating_area <chr>,\n#   ou_publication_date <chr>, perspective <chr>, prel_publication_date <chr>,\n#   publ_period <chr>, publication_date <chr>, title <chr>\n\n\nVi kan filtrera dessa med dplyr och stringr eller använda den inbyggda funktionen kpi_search():\n\nkpi_bygglov <- kpi_search(kpis, c(\"bostäder som beviljats bygglov\"), column = \"description\")\n\nkpi_bygglov\n\n# A tibble: 1 × 13\n  auspices description       has_ou_data id    is_divided_by_g… municipality_ty…\n  <chr>    <chr>             <lgl>       <chr>            <int> <chr>           \n1 X        Antal bostäder s… FALSE       N079…                0 K               \n# … with 7 more variables: operating_area <chr>, ou_publication_date <chr>,\n#   perspective <chr>, prel_publication_date <chr>, publ_period <chr>,\n#   publication_date <chr>, title <chr>\n\n\nFör att få ner data för detta KPI behöver 1) ett ID och 2) specificera vilken eller vilka kommuner du vill ha data för.\nID får du enkelt ut genom kpi_extract_ids().\n\nkpi_extract_ids(kpi_bygglov)\n\n[1] \"N07925\"\n\n\nDe kommuner, eller regionala indelningar som finns, kan vi på motsvarande sätt få genom get_municipality().\n\nget_municipality()\n\n# A tibble: 312 × 3\n   id    title      type \n   <chr> <chr>      <chr>\n 1 1440  Ale        K    \n 2 1489  Alingsås   K    \n 3 0764  Alvesta    K    \n 4 0604  Aneby      K    \n 5 1984  Arboga     K    \n 6 2506  Arjeplog   K    \n 7 2505  Arvidsjaur K    \n 8 1784  Arvika     K    \n 9 1882  Askersund  K    \n10 2084  Avesta     K    \n# … with 302 more rows\n\n\nEn bra sak med Kolada är att de för alla Sveriges kommuner har referenskommuner, kommuner som på olika sätt liknar kommunen du är intresserad av. På så sätt kan vi enkelt ta fram kommuner som är relevanta att jämföra med. I rKolada gör vi det med get_municipality_groups() och den tillhörande search-funktionen.\n\nget_municipality_groups() %>% \n  municipality_grp_search(\"Finspång\")\n\n# A tibble: 11 × 3\n   id      members      title                                               \n   <chr>   <list>       <chr>                                               \n 1 G175948 <df [7 × 2]> Liknande kommuner ekonomiskt bistånd, Finspång, 2020\n 2 G176238 <df [7 × 2]> Liknande kommuner socioekonomi, Finspång, 2020      \n 3 G176528 <df [7 × 2]> Liknande kommuner äldreomsorg, Finspång, 2021       \n 4 G35908  <df [7 × 2]> Liknande kommuner grundskola, Finspång, 2021        \n 5 G36200  <df [7 × 2]> Liknande kommuner gymnasieskola, Finspång, 2021     \n 6 G36492  <df [7 × 2]> Liknande kommuner IFO, Finspång, 2021               \n 7 G37368  <df [7 × 2]> Liknande kommuner, övergripande, Finspång, 2021     \n 8 G39541  <df [7 × 2]> Liknande kommuner LSS, Finspång, 2021               \n 9 G85502  <df [7 × 2]> Liknande kommuner fritidshem, Finspång, 2021        \n10 G85794  <df [7 × 2]> Liknande kommuner förskola, Finspång, 2021          \n11 G87668  <df [7 × 2]> Liknande kommuner integration, Finspång, 2021       \n\n\nI slutändan har vi nu all metadata vi behöver och vill då få in den faktiska datan. För att få tag i den använder vi bara get_values(), då får vi tillbaka en data.frame med all data som vi frågat efter.\n\nkpi_id <- kpi_search(kpis, c(\"bostäder som beviljats bygglov\"),\n                                  column = \"description\") %>% \n  kpi_extract_ids()\n\nmunic_grp <- get_municipality_groups() %>%\n  municipality_grp_search(\"Liknande kommuner socioekonomi, Finspång\") %>% \n  municipality_grp_extract_ids()\n\nfinspang_id <- get_municipality() %>%\n  municipality_search(\"Finspång\") %>% \n  municipality_extract_ids()\n\n# Get values\ngrp_data <- get_values(\n  kpi = kpi_id,\n  municipality = c(\n    munic_grp,\n    finspang_id\n  )\n)\n\ngrp_data\n\n# A tibble: 56 × 8\n   kpi    municipality_id  year count gender value municipality municipality_ty…\n   <chr>  <chr>           <int> <int> <chr>  <dbl> <chr>        <chr>           \n 1 N07925 0562             2015     1 T       0.7  Finspång     K               \n 2 N07925 1272             2015     1 T       6    Bromölla     K               \n 3 N07925 1273             2015     1 T       1.8  Osby         K               \n 4 N07925 1884             2015     1 T       3    Nora         K               \n 5 N07925 1885             2015     1 T       5.6  Lindesberg   K               \n 6 N07925 1961             2015     1 T       3.6  Hallstahamm… K               \n 7 N07925 1981             2015     1 T       3.8  Sala         K               \n 8 N07925 1984             2015     1 T       0.9  Arboga       K               \n 9 N07925 0562             2016     1 T       3.62 Finspång     K               \n10 N07925 1272             2016     1 T       5.15 Bromölla     K               \n# … with 46 more rows\n\n\nVi har nu data som antingen kan visualiseras, inkluderas i en Rmarkdown-genererad PDF-rapport, skrivas till en Excel, PowerPoint, lagra i en databas med mera.\nHär nöjer vi oss med en enkel visualisering:\n\nggplot(grp_data, aes(x = year, y = value, color = municipality)) +\n  geom_line() +\n  labs(\n    title = \"Antal bostäder som beviljats bygglov under två senaste åren\",\n    subtitle = \"Antal/100 invånare\",\n    caption = \"Källa: SKR och SCB\",\n    y = \"Antal/1000 invånare\",\n    x = \"År\",\n    color = \"Kommun\"\n  ) +\n  theme_minimal() +\n  ggthemes::scale_color_colorblind()\n\n\n\n\nEtt stort tack till Love Hansson som lagt tid på att designa ett paket som jag tror kan underlätta för många analytiker på myndigheter, universitet och ute bland Sveriges kommuner och landsting.\n/ Filip"
  },
  {
    "objectID": "posts/2020-05-08-automate-ppts/2020-05-08-automate-ppts.html",
    "href": "posts/2020-05-08-automate-ppts/2020-05-08-automate-ppts.html",
    "title": "Automatisera PowerPoints med R",
    "section": "",
    "text": "Jag skulle påstå att PowerPoint tillsammans med Excel är det överlägset vanligaste sättet att rapportera analytiska resultat. I min roll som konsult har jag träffat många analytiker som önskar att de kunde lägga mindre tid på att ta fram PowerPoints och mer tid på faktisk analys.\nMed paketet officer kan du enkelt skapa PowerPoints från R och dessutom utnyttja din organisations mall.\nFörst behöver vi lite data. Den tar vi ner från Tilastokeskus - Finlands statistikcentral med hjälp av paketet pxweb. Nedan hämtar vi data för befokningsmängden i Finland sedan 1750.\n\nlibrary(pxweb)\n\npxweb 0.13.1: R tools for the PX-WEB API.\nhttps://github.com/ropengov/pxweb\n\npxweb_query_list <- \n  list(\"Vuosi\"= as.character(1750:2021),\n       \"Sukupuoli\"=c(\"SSS\"),\n       \"Tiedot\"=c(\"vaesto\"))\n\n# Download data \npx_data <- \n  pxweb_get(url = \"https://statfin.stat.fi/PXWeb/api/v1/sv/StatFin/vaerak/statfin_vaerak_pxt_11rb.px\",\n            query = pxweb_query_list)\n\n# Convert to data.frame \npx_data_frame <- as.data.frame(px_data, column.name.type = \"text\", variable.value.type = \"text\")\n\nhead(px_data_frame)\n\n    År    Kön Befolkning 31.12.\n1 1750 Totalt            421500\n2 1751 Totalt            429900\n3 1752 Totalt            437600\n4 1753 Totalt            445300\n5 1754 Totalt            450100\n6 1755 Totalt            457800\n\n\nNästa steg är att städa data lite.\n\nlibrary(dplyr, warn.conflicts = FALSE)\n\nWarning: package 'dplyr' was built under R version 4.1.2\n\nlibrary(janitor, warn.conflicts = FALSE) ## Paket för att bland annat städa upp namn på kolumner \npopulation_df <- px_data_frame %>%\n  janitor::clean_names() %>% \n  rename(year = ar, population = befolkning_31_12) %>%\n  mutate(year = as.numeric(year))\n\nI min visualisering använder jag paketet hrbrthemes som har ett tema jag tycker om.\n\n# Cite the data as \nlibrary(ggplot2)\nlibrary(hrbrthemes)\npopulation_plot <- population_df %>% \n    ggplot(aes(year, population)) +\n    geom_line(size = 2) +\n    scale_y_continuous(labels = scales::number) +\n    theme_ipsum(base_size = 20,\n                                                    plot_title_size = 40,\n                                                    subtitle_size = 30,\n                                                    caption_size = 15,\n                                                    axis_title_size = 15) +\n    labs(\n        title = \"Size of Finnish population since 1750\",\n        subtitle = \"At the 31st of December every year\",\n        x = \"Year\",\n        y = \"Size of population\",\n        caption = \"Source: Tilastokeskus/Statistikcentralen i Finland\"\n    ) +\n    theme(text = element_text(size = 50))\n\npopulation_plot\n\n\n\n\nVisualiseringen är lite stor, men den kommer att se bättre ut i en PowerPoint.\nNu ska vi lägga in det här i en powerpoint. För att göra det använder jag paketet officer.\nI slutet av förra året gick det företag jag arbetar för Ferrologic Analytics samman med ett finskt bolag som heter Solita. Så jag tänkte att jag kunde använda deras PowerPoint-mall för att skapa PowerPointen.\nFörst läser jag in PowerPoint-filen och undersöker dess layouts. Dessa motsvarar valen du kan göra när du klickar på Ny slide i PowerPoint.\n\nlibrary(officer)\nsolita_pres <- read_pptx(\"solita-pres-mall.pptx\")\n\nlayout_summary(solita_pres) %>% \n  head()\n\n            layout master\n1       Otsikkodia Solita\n2 Osan ylätunniste Solita\n3 Section Header 2 Solita\n4 Section Header 3 Solita\n5 Section Header 4 Solita\n6 Section Header 5 Solita\n\n\nSom ni ser är layout-formatteringen på finska, men öppnar du PowerPoint-filen ser du att Otsikkodia står för Titel-slide.\nVarje layout har så kallade placeholders som är fördefinierade rutor gjorda för grafer, text, tabeller m.m.\n\nlayout_properties(solita_pres, \"Otsikkodia\")\n\n   master_name       name     type id   ph_label\n4       Solita Otsikkodia     body 10  Graphic 4\n7       Solita Otsikkodia     body  6  Graphic 8\n74      Solita Otsikkodia ctrTitle  2    Title 1\n75      Solita Otsikkodia subTitle  3 Subtitle 2\n                                ph      offx     offy        cx        cy\n4                             <NA> 0.6692913 1.929134 11.732283 5.0787402\n7                             <NA> 0.6692913 1.929134 11.732283 5.0787402\n74         <p:ph type=\"ctrTitle\"/> 0.8858257 2.283465 11.529104 3.7795276\n75 <p:ph type=\"subTitle\" idx=\"1\"/> 0.8858268 6.358268  9.421979 0.6299213\n\n\nGenom att ta en graf och lägga den i en placeholder kommer R alltid att skala grafen korrekt och du behöver inte oroa dig över bredd, höjd eller upplösning.\nVi börjar med att lägga till en titel-slide, notera här att vi använder ph_location_type för att identifiera vår placeholder type ctrTitle.\n\nppt_pres <- solita_pres %>% \n    add_slide(layout = \"Otsikkodia\", master = \"Solita\") %>% \n    ph_with(value = \"Made In R\", location = ph_location_type(type = \"ctrTitle\"))\n\nFör att lägga till vår graf använder vi oss av en annan layout men här använder ph_location_fullsize som helt enkelt tar grafen och gör så att den tar upp hela vår slide. Vi hade också kunnat specificera en location här.\n\nppt_pres <- ppt_pres %>% \n  add_slide(layout = \"Otsikko ja sisältö\", master = \"Solita\") %>% \n    ph_with(value = population_plot,\n                                    location = ph_location_fullsize())\n\nSlutligen printar vi hela presentationen:\n\nprint(ppt_pres, \"solita-forest-pres.pptx\")\n\nSom kommer att se ut så här:"
  },
  {
    "objectID": "posts/2021-06-03-gis-i-r/gis-i-r.html",
    "href": "posts/2021-06-03-gis-i-r/gis-i-r.html",
    "title": "GIS och Kartor i R",
    "section": "",
    "text": "Geografiska informationssystem eller GIS är ett stort område inom dataanalys som traditionellt endast varit möjligt i mjukvaruprogram med höga licenskostnader. Men med den senaste tidens explosion av mjukvara som är Open Source är det idag möjligt att göra minst lika avancerade analyser helt kostnadsfritt. Här tänkte jag visa hur vi kan använda paket i R för att göra GIS.\nVi utgår från kartdata från SCB, som ni hittar här. Dessa filer finns inbygga i paketet swemaps2. Men om du vill läsa in dessa filer laddar du först ner dem som zip-filer och unzippa.\n\ndownload.file(\"https://www.scb.se/contentassets/3443fea3fa6640f7a57ea15d9a372d33/shape_svenska.zip\", destfile = \"shape_svenska.zip\")\n\nunzip(\"shape_svenska.zip\", exdir = \"shape_svenska\")\n\nunzip(\"shape_svenska/LanRT90.zip\", exdir = \"lan_rt90\")\n\nDå får vi dessa filer i mappen lan_rt90.\n\nlist.files(\"lan_rt90\")\n\n[1] \"Lan_RT90_region.dbf\" \"Lan_RT90_region.prj\" \"Lan_RT90_region.shp\"\n[4] \"Lan_RT90_region.shx\"\n\n\nViktigt att notera är att du behöver alla filer i mappen för att ladda in geografisk data till R. Men du behöver bara ladda in en av filerna, nämligen den som är Shape (.shp).\nFör att läsa in och bearbeta kartfiler använder vi paktet sf(Simple Features) som gör det enkelt att läsa in och manipulera kartfiler.\nVi laddar in shape-filen med read_sf() och ser då att varje län har en geometry, en multipolygon, som är gränserna för länet.\n\nlibrary(sf)\n\nLinking to GEOS 3.10.2, GDAL 3.4.2, PROJ 8.2.1; sf_use_s2() is TRUE\n\nlan <- read_sf(\"lan_rt90/Lan_RT90_region.shp\")\n\nlan\n\nSimple feature collection with 21 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 1230810 ymin: 6137234 xmax: 1880916 ymax: 7669583\nProjected CRS: RT90 2.5 gon V\n# A tibble: 21 × 3\n   LnKod LnNamn                                                         geometry\n   <chr> <chr>                                                <MULTIPOLYGON [m]>\n 1 01    Stockholms    (((1581896 6569894, 1584367 6572819, 1585410 6571048, 15…\n 2 03    Uppsala       (((1588105 6611272, 1587491 6610219, 1591541 6601881, 15…\n 3 04    Södermanlands (((1508793 6538144, 1503218 6541877, 1502168 6544820, 14…\n 4 05    Östergötlands (((1448643 6445587, 1446285 6441023, 1438051 6439351, 14…\n 5 06    Jönköpings    (((1451287 6423652, 1452508 6419347, 1456711 6414227, 14…\n 6 07    Kronobergs    (((1455396 6340554, 1456478 6342310, 1460661 6342030, 14…\n 7 08    Kalmar        (((1495818 6327165, 1491423 6329015, 1489201 6333906, 14…\n 8 09    Gotlands      (((1658877 6415526, 1662237 6416751, 1664956 6417647, 16…\n 9 10    Blekinge      (((1423434 6230844, 1422094 6233619, 1418608 6233013, 14…\n10 12    Skåne         (((1370410 6257557, 1375642 6259726, 1380641 6259554, 13…\n# … with 11 more rows\n\n\nFör att visualisera det här krävs inget mer än att använda ggplot2 tillsammans med geom_sf() på data.\n\nlibrary(tidyverse)\nggplot(lan) +\n  geom_sf()\n\n\n\n\nMed geom_sf() får vi ett koordinatsystem med longitude och latitude, men vill vi bara ha en “clean” karta kan vi exempelvis använda theme_map() från paketet ggthemes.\n\nlibrary(ggthemes)\nggplot(lan) +\n  geom_sf() +\n  theme_map()\n\n\n\n\nI längden vill vi dock fylla den här kartan med någon slags information. Vi vänder oss då till SCB med paketet pxweb, som är ett paket för att hämta data från SCB direkt till R. Koden nedan är i huvudsak genererad från funktionen pxweb_interactive(), som vi använt för att interaktivt prata med SCB:s API. Nedan har jag tagit ner data för antalet personer eftergymnasial utbildning per län samt befolkning, för att kunna visualisera andelen i regionen med eftergymnasial utbildning.\nÄr du intresserad av hur man hämtar data från SCB till R har jag skrivit ett inlägg om det här. Är du inte intresserad av hur vi hämtar data kan du bara hoppa över det här kodblocket.\n\nlibrary(pxweb)\nlibrary(janitor)\n\npxweb_query_list <- list(\n  \"Region\"= lan$LnKod, ## Här använder jag länskoder från shape-filen för att få ner alla län\n  \"Kon\"=c(\"1\",\"2\"),\n  \"ContentsCode\"=c(\"000000I2\"),\n  \"Tid\"=c(\"2019\"))\n\npxweb_query_list <- \n  list(\"Region\"= lan$LnKod,\n       \"Alder\"=c(\"tot\"),\n       \"Kon\"=c(\"1\",\"2\"),\n       \"ContentsCode\"=c(\"BE0101A9\"),\n       \"Tid\"=c(\"2022\"))\n\n# Download data \npx_data <- \n  pxweb_get(url = \"https://api.scb.se/OV0104/v1/doris/sv/ssd/BE/BE0101/BE0101A/FolkmangdNov\",\n            query = pxweb_query_list)\n\n# Convert to data.frame \npx_data_frame <- as.data.frame(px_data, column.name.type = \"text\", variable.value.type = \"text\")\n\n## Vi är bara ute efter att visualisera totalen per region, inte på åldersnivå, därför summerar jag per region\npx_data_clean <- px_data_frame %>% \n  janitor::clean_names() %>% \n  group_by(region) %>% \n  summarise(folkmangd_2022 = sum(folkmangden_den_1_november))\n\nNu har vi data som vi kan joina på vår geografiska data. Ett problem är dock att vi i data från SCB:s API inte fått med länskoder. Det löser jag genom att rensa bort strängen \" län\" med str_replace(). Formatetet på länsnamn är då detsamma och vi kan joina på den geografiska information och visualisera andel personer med eftergymnasial utbildning per län.\n\npx_data_geo <- px_data_clean %>% \n  mutate(region = str_replace(region, \" län\", \"\")) %>% \n  left_join(lan, by = c(\"region\" = \"LnNamn\"))\n\nNu kan vi visualisera resultatet:\n\nggplot(px_data_geo, aes(fill = folkmangd_2022)) +\n  geom_sf(aes(geometry = geometry)) +\n  theme_map() +\n  theme(legend.position = c(1, 0.15)) +\n  scale_fill_viridis_c(option = \"magma\",\n                       labels = scales::number_format(accuracy = 1),\n                       direction = -1) +\n  labs(\n    title = \"Folkmängd per län\",\n    caption = \"Källa: SCB\",\n    fill = \"Total folkmängd 1 november\"\n  )\n\n\n\n\nVisualiseringen kan vi sedan spara som en png-fil.\n\nggsave(\"scb-karta-eftergymn.png\")"
  },
  {
    "objectID": "posts/2020-06-08-data-from-scb/data-from-scb.html",
    "href": "posts/2020-06-08-data-from-scb/data-from-scb.html",
    "title": "Hämta data från SCB till R",
    "section": "",
    "text": "Visste du att du kan hämta data direkt från SCB, Statistiska centralbyrån till R?\nDu behöver alltså inte gå in i statistikdatabasen och ta ut en ny Excel-tabell varje gång du ska uppdatera SCB-statistik utan kan istället låta paketet pxweb av Måns Magnusson ställa frågor mot SCB:s API och få koden för det. Perfekt om ens verksamhet använder offentlig statistik återkommande.\nMed den interaktiva funktionen pxweb_interactive() kan vi prata med SCB:s (och flera andra nationella statistikcentraler) API.\nJag brukar först använda statistikdatabsen för att hitta det jag söker och sedan navigera mig till det genom pxweb, som följer samma struktur som hemsidan.\nDu laddar ner paketet med install.packages(\"pxweb\").\n\nlibrary(pxweb)\n\npxweb_interactive()\n\n\n\npxweb 0.13.1: R tools for the PX-WEB API.\nhttps://github.com/ropengov/pxweb\n\n\nNär du klickat dig fram till den statistik du är intresserad av får du koden för att ladda ner data programmatiskt.\n\npxweb_query_list <- list(\"Kon\"=c(\"1\", \"2\"), \n                         \"ContentsCode\"=c(\"000000MD\",\"000000ME\"),\n                         \"Tid\"=c(\"1968\",\"1969\",\"1970\",\"1971\",\"1972\",\n                                 \"1973\",\"1974\",\"1975\",\"1976\",\"1977\",\"1978\",\n                                 \"1979\",\"1980\",\"1981\",\"1982\",\"1983\",\"1984\",\n                                 \"1985\",\"1986\",\"1987\",\"1988\",\"1989\",\"1990\",\n                                 \"1991\",\"1992\",\"1993\",\"1994\",\"1995\",\"1996\",\n                                 \"1997\",\"1998\",\"1999\",\"2000\",\"2001\",\"2002\",\n                                 \"2003\",\"2004\",\"2005\",\"2006\",\"2007\",\"2008\",\n                                 \"2009\",\"2010\",\"2011\",\"2012\",\"2013\",\"2014\",\n                                 \"2015\",\"2016\",\"2017\",\"2018\",\"2019\"))\n\n# Download data \npx_data <- \n  pxweb_get(url = \"http://api.scb.se/OV0104/v1/doris/sv/ssd/BE/BE0101/BE0101B/BefolkMedianAlder\",\n            query = pxweb_query_list)\n\n# Convert to data.frame \npx_df <- as.data.frame(px_data, column.name.type = \"text\", variable.value.type = \"text\")\n\nNu kan vi visualisera data, exportera den eller göra vad vi nu vill med den.\n\nlibrary(tidyverse)\nlibrary(glue)\nlibrary(scales)\n\nmin_år <- min(as.numeric(px_df$år))\nmax_år <- max(as.numeric(px_df$år))\n\npx_df %>% \n  mutate(år = as.numeric(år)) %>% \n  ggplot(aes(år, Medianålder, color = kön)) +\n  geom_line() +\n  labs(\n    title = \"Medianålder i Sverige\",\n    subtitle = glue(\"Från {min_år}-{max_år}\"),\n    x = \"\"\n  ) +\n  scale_y_continuous(limits = c(0, 50), labels = number_format(suffix = \" år\")) +\n  scale_x_continuous(breaks = pretty_breaks(10)) +\n  theme_minimal()"
  },
  {
    "objectID": "posts/2022-09-19-analysera-valet/analysera-valet.html",
    "href": "posts/2022-09-19-analysera-valet/analysera-valet.html",
    "title": "Kartor över valdistrikt i R",
    "section": "",
    "text": "Det har gått mer än en vecka sedan valet och resultatdata har nu börjat publiceras på valmyndigheten.se. I det här inlägget tänkte jag visa hur vi kan använda swemaps2 för att analysera valresultatet på kommunal nivå.\nTill att börja med kan vi ladda ner valresutlatet som finns i en Excel på valmyndigheten.se\n\nlibrary(readxl)\nlibrary(tidyverse)\n\ndownload.file(\"https://www.val.se/download/18.14c1f613181ed0043d567ae/1663009000443/valresultat-riksdagen-preliminar-jamforande-statistik.xlsx\",\n              destfile = \"data/valresultat-riksdagen-preliminar-jamforande-statistik.xlsx\")\n\nvalresultat <- read_excel(\"data/valresultat-riksdagen-preliminar-jamforande-statistik.xlsx\", sheet = 3) |> \n  janitor::clean_names() \n\nvalresultat\n\n# A tibble: 4,350 × 9\n   riksdagsvalkrets kommu…¹ parti roste…² andel…³  diff diff_a…⁴ roste…⁵ andel…⁶\n   <chr>            <chr>   <chr>   <dbl>   <dbl> <dbl>    <dbl>   <dbl>   <dbl>\n 1 Västra Götaland… Ale     Mode…    3451  0.182   -188 -0.00588    3639  0.188 \n 2 Västra Götaland… Ale     Cent…     994  0.0525  -364 -0.0177     1358  0.0703\n 3 Västra Götaland… Ale     Libe…     631  0.0333  -283 -0.0139      914  0.0473\n 4 Västra Götaland… Ale     Kris…    1065  0.0563  -147 -0.00642    1212  0.0627\n 5 Västra Götaland… Ale     Arbe…    5687  0.301    286  0.0211     5401  0.279 \n 6 Västra Götaland… Ale     Väns…    1259  0.0665  -219 -0.00993    1478  0.0765\n 7 Västra Götaland… Ale     Milj…     664  0.0351   -95 -0.00417     759  0.0393\n 8 Västra Götaland… Ale     Sver…    4864  0.257    563  0.0346     4301  0.223 \n 9 Västra Götaland… Ale     Övri…     307  0.0162    39  0.00236     268  0.0139\n10 Västra Götaland… Ale     Gilt…   18922  1       -408 NA         19330  1     \n# … with 4,340 more rows, and abbreviated variable names ¹​kommunnamn,\n#   ²​roster_2022, ³​andel_2022, ⁴​diff_andel, ⁵​roster_2018, ⁶​andel_2018\n\n\nVi ser att det i kolumnen parti finns en del värden som inte är partier, ex. Röstberättigande.\n\nvalresultat |> \n  group_by(parti) |> \n  summarise(roster_2022 = sum(roster_2022)) |> \n  arrange(desc(roster_2022))\n\n# A tibble: 15 × 2\n   parti                                  roster_2022\n   <chr>                                        <dbl>\n 1 Röstberättigade                            7772120\n 2 Valdeltagande vallokaler                   6320963\n 3 Giltiga Röster                             6227229\n 4 Arbetarepartiet-Socialdemokraterna         1897965\n 5 Sverigedemokraterna                        1282352\n 6 Moderaterna                                1187350\n 7 Centerpartiet                               417851\n 8 Vänsterpartiet                              414604\n 9 Kristdemokraterna                           333327\n10 Miljöpartiet de gröna                       314579\n11 Liberalerna (tidigare Folkpartiet)          286503\n12 Övriga anmälda partier                       92698\n13 Ogiltiga röster - blanka                     59218\n14 Ogiltiga röster - övriga                     31137\n15 Ogiltiga röster - inte anmälda partier        3379\n\n\nVi är bara intresserade av de stora riksdagspartierna, så vi filtrerar bort värden som inte är partier.\n\nlibrary(stringr)\nvalresultat_partier <- valresultat |> \n  filter(!(parti %in% c(\"Röstberättigade\",\n                        \"Valdeltagande vallokaler\",\n                        \"Giltiga Röster\")) &\n           !str_detect(parti, \"Ogiltiga\"))\n\nFör att kunna redovisa resultatet på en karta behöver vi knyta det till ett geografiskt objekt. Det kan vi enkelt göra genom att joina vår data.frame med municipality som är ett dataset i swemaps2.\n\nlibrary(swemaps2)\nvalresultat_kommun <- swemaps2::municipality |> \n  left_join(\n    valresultat_partier, by = c(\"kn_namn\" = \"kommunnamn\")\n  )\n\nvalresultat_kommun\n\nSimple feature collection with 2602 features and 12 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 1230810 ymin: 6137234 xmax: 1880916 ymax: 7669583\nProjected CRS: RT90 2.5 gon V\n# A tibble: 2,602 × 13\n   kn_kod kn_namn ln_kod ln_namn                  geometry riksd…¹ parti roste…²\n   <chr>  <chr>   <chr>  <chr>          <MULTIPOLYGON [m]> <chr>   <chr>   <dbl>\n 1 0114   Upplan… 01     Stockh… (((1620218 6599562, 1618… Stockh… Mode…    5043\n 2 0114   Upplan… 01     Stockh… (((1620218 6599562, 1618… Stockh… Cent…    1461\n 3 0114   Upplan… 01     Stockh… (((1620218 6599562, 1618… Stockh… Libe…    1126\n 4 0114   Upplan… 01     Stockh… (((1620218 6599562, 1618… Stockh… Kris…    1194\n 5 0114   Upplan… 01     Stockh… (((1620218 6599562, 1618… Stockh… Arbe…    7389\n 6 0114   Upplan… 01     Stockh… (((1620218 6599562, 1618… Stockh… Väns…    1805\n 7 0114   Upplan… 01     Stockh… (((1620218 6599562, 1618… Stockh… Milj…     894\n 8 0114   Upplan… 01     Stockh… (((1620218 6599562, 1618… Stockh… Sver…    5205\n 9 0114   Upplan… 01     Stockh… (((1620218 6599562, 1618… Stockh… Övri…     450\n10 0115   Vallen… 01     Stockh… (((1637371 6601120, 1636… Stockh… Mode…    5272\n# … with 2,592 more rows, 5 more variables: andel_2022 <dbl>, diff <dbl>,\n#   diff_andel <dbl>, roster_2018 <dbl>, andel_2018 <dbl>, and abbreviated\n#   variable names ¹​riksdagsvalkrets, ²​roster_2022\n\n\nJag är intresserad av hur det gått för Moderaterna i Skåne så jag filtrerar ut Skåne och moderaterna.\n\nvalresultat_skane <- valresultat_kommun |> \n  filter(parti == \"Moderaterna\" & str_detect(tolower(ln_namn), \"skåne\"))\n\nNu har vi valresultat knutet till geografiska objekt och kan visualisera det.\n\nlibrary(scales)\n\n\nAttaching package: 'scales'\n\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nplot_skane <- valresultat_skane |> \n  ggplot(aes(fill = diff_andel)) +\n  geom_sf() +\n  scale_fill_viridis_c(option = \"magma\", label = scales::percent) +\n  theme_swemap2()\n\nplot_skane\n\n\n\n\nFör att göra visualiseringen lite mer informativ kan vi skapa en dataframe där vi har de kommuner där Moderaterna tappat mest och där det ökat mest.\n\ntop_skane <- valresultat_skane |> \n  slice_max(diff_andel, n = 3)\n\nbottom_skane <- valresultat_skane |> \n  slice_min(diff_andel, n = 3)\n\nlabels_skane <- bind_rows(top_skane, bottom_skane)\n\nFör att skapa snygga labels använder jag ggrepel. Vi ser att Bromölla är den kommun där moderaterna gått framåt. Annars ser de ut att tappa i de flesta kommuner.\n\nlibrary(ggrepel)\nplot_skane <- plot_skane +\n  geom_label_repel(\n    data = labels_skane,\n    aes(label = kn_namn, geometry = geometry),\n    stat = \"sf_coordinates\",\n    min.segment.length = 0,\n    color = \"black\",\n    fill = \"white\"\n  ) \n\nplot_skane\n\n\n\n\nTill sist ändrar jag titel och lite andra parametrar för att få en mer tilltalande visualisering:\n\nplot_skane +\n  labs(\n    title = \"Förändring andel röster för Moderaterna\",\n    subtitle = \"2018 till 2022\",\n    fill = \"Skillnad\",\n    caption = \"Källa: Valmyndigheten och SCB\"\n  )"
  },
  {
    "objectID": "posts/2020-04-19-testscores-in-r/excel-testscores-in-r.html",
    "href": "posts/2020-04-19-testscores-in-r/excel-testscores-in-r.html",
    "title": "Översätt provresultat från Excel till betyg i R",
    "section": "",
    "text": "Jag har länge varit imponerad av David Stavegård och hans #torsdagstips i Excel där han med konkreta exempel visar hur man löser verkliga databearbetningsproblem med Excel.\nJag har tagit mig friheten att översatta några av dessa #torsdagstips till hur jag skulle lösa dem i programmeringsspråket R.\nI det här torsdagstipset har vi Excel-fil med provresultat från en klass och vi vill göra om resultaten till betyg. I Excel använder David funktionen ifs(). I R använder vi funktionen case_when() från paketet dplyr.\nVi laddar paketet tidyverse innehåller flera bra funktioner för vårt problem.\nDet här problemet kanske låter banalt, men för mig var det här en av de svårare sakerna att göra när jag började programmera i R. Men så är det, det som känns enkelt idag var svårt igår.\nVi vet att provresultatet ska leda till följande betyg:\nI mappen data har vi 24 olika klasser med provresultat.\nVi kan läsa in en klass med read_excel():\nFör att skriva flera “if-else” kan vi använda funktionen case_when() i mutate(), båda från paketet dplyr som laddats i tidyverse.\nVi kan sedan skriva resultatet till mappen provresultat om vi vill ha slutresultatet i Excel."
  },
  {
    "objectID": "posts/2020-04-19-testscores-in-r/excel-testscores-in-r.html#varför-göra-det-här-i-r",
    "href": "posts/2020-04-19-testscores-in-r/excel-testscores-in-r.html#varför-göra-det-här-i-r",
    "title": "Översätt provresultat från Excel till betyg i R",
    "section": "Varför göra det här i R?",
    "text": "Varför göra det här i R?\nGenom att skriva det här som ett skript kan du enkelt byta ut din datafil och kör om resultatet och på så sätt spara tid.\nEtt ännu mer effektivt sätt är att iterera över alla klasser, översätta deras resultat till betyg och sedan skriva allt till en Excel, med en flik för varje klass.\nVi börjar meda att skriva en egen funktion:\n\nlibrary(stringr)\n\nread_klass <- function(path){\n  data <- read_excel(path)\n  \n  data$klass <- str_extract(path, \"klass_[:digit:]+\")\n  \n  data\n}\n\nread_klass(\"data/klass_4.xlsx\")\n\n# A tibble: 30 × 3\n   namn        provresultat klass  \n   <chr>              <dbl> <chr>  \n 1 Mahsuni               41 klass_4\n 2 Aldiona               57 klass_4\n 3 Mervis                49 klass_4\n 4 Niangi                42 klass_4\n 5 Laxmi                 48 klass_4\n 6 Helgevold             44 klass_4\n 7 Yayah                100 klass_4\n 8 Irgens                93 klass_4\n 9 Frans-Lukas           82 klass_4\n10 Stålis                57 klass_4\n# … with 20 more rows\n\n\nVi kan iterera den här funktionen över alla klasser och läsa in allt till en data.frame med map_df() från paketet purrr (också från tidyverse).\n\nlibrary(purrr)\n\nklasser <- map_df(data_filer, read_klass)\n\nklasser\n\n# A tibble: 720 × 3\n   namn      provresultat klass  \n   <chr>            <dbl> <chr>  \n 1 Nanay               95 klass_1\n 2 Manoshak            79 klass_1\n 3 Albano              58 klass_1\n 4 Minotti             61 klass_1\n 5 Dahlith             73 klass_1\n 6 Lillebror           80 klass_1\n 7 Maasum              74 klass_1\n 8 Winner              71 klass_1\n 9 Lilleby             91 klass_1\n10 Ratu                58 klass_1\n# … with 710 more rows\n\n\nVi kan enkelt applicera vår betygomräknare till alla klasser:\n\nklasser <- klasser %>% \n  mutate(betyg = case_when(\n    provresultat >= 95 ~ \"A\",\n    provresultat >= 85 ~ \"B\",\n    provresultat >= 75 ~ \"C\",\n    provresultat >= 65 ~ \"D\",\n    provresultat >= 55 ~ \"E\",\n    provresultat < 55 ~ \"F\",\n  ))\n\nklasser\n\n# A tibble: 720 × 4\n   namn      provresultat klass   betyg\n   <chr>            <dbl> <chr>   <chr>\n 1 Nanay               95 klass_1 A    \n 2 Manoshak            79 klass_1 C    \n 3 Albano              58 klass_1 E    \n 4 Minotti             61 klass_1 E    \n 5 Dahlith             73 klass_1 D    \n 6 Lillebror           80 klass_1 C    \n 7 Maasum              74 klass_1 D    \n 8 Winner              71 klass_1 D    \n 9 Lilleby             91 klass_1 B    \n10 Ratu                58 klass_1 E    \n# … with 710 more rows\n\n\nNu kan vi spara ner alla betyg till en Excel där varje klass får en egen flik.\n\nlibrary(openxlsx)\n\nwb <- createWorkbook()\n\nklass_till_excel <- function(klass){\n  klass_df <- filter(klasser, klass == !!klass)\n  \n  addWorksheet(wb, sheetName = klass)\n  \n  writeData(wb, sheet = klass, klass_df)\n  \n}\n\nunika_klasser <- unique(klasser$klass)\n\nklasser_wb <- map(unika_klasser, klass_till_excel)\n\nsaveWorkbook(wb, \"provresultat/klasser-provresutlat.xlsx\", overwrite = TRUE)\n\n\nSå enkelt och effektivt!"
  },
  {
    "objectID": "posts/2020-04-19-testscores-in-r/excel-testscores-in-r.html#appendix-skapa-klasserna",
    "href": "posts/2020-04-19-testscores-in-r/excel-testscores-in-r.html#appendix-skapa-klasserna",
    "title": "Översätt provresultat från Excel till betyg i R",
    "section": "Appendix: Skapa klasserna",
    "text": "Appendix: Skapa klasserna\nVi kan börja med att generera en slumpmässig fil med provresultat. Tack vara Peter Dahlgren på Stockholm universitet, som lagt upp en fil med svenska namn, kan vi generera 30 svenska kill- och tjejnamn utan att först behöva skriva dem.\nJag har skapat en enkel funktion för det här som heter skapa_klass() som skapar ett fiktivt dataset med provresultat för \\(n\\) antal elever. Är du nyfiken kan du läsa den nedan, annars är det bara att hoppa över.\n\nskapa_klass <- function(antal_elever = 30){\n  män <- read_csv(\"https://raw.githubusercontent.com/peterdalle/svensktext/master/namn/fornamn-man.csv\",\n                  col_names = FALSE, locale = locale(encoding = \"UTF-8\"))\n  kvinnor <- read_csv(\"https://raw.githubusercontent.com/peterdalle/svensktext/master/namn/fornamn-kvinnor.csv\",\n                      col_names = FALSE, locale = locale(encoding = \"UTF-8\"))\n  \n  alla_namn <- bind_rows(män, kvinnor) %>% \n    rename(namn = X1)\n  \n  klass <- tibble(\n    namn = sample(alla_namn$namn, 30, replace = TRUE),\n    provresultat = sample(c(40:100), 30, replace = TRUE))\n  \n  klass\n}\n\nNedan skapar vi enkelt klasserna.\n\nlibrary(openxlsx)\nskriv_klass <- function(nr){\n  klass <- skapa_klass(30)\n  \n  klass_file <- paste0(\"data/klass\", \"_\", nr, \".xlsx\")\n  \n  write.xlsx(klass, klass_file)\n}\n\nmap(1:24, skriv_klass)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "filipwastberg",
    "section": "",
    "text": "Python in Quarto\n\n\n\n\n\n\n\npython\n\n\n\n\n\n\n\n\n\n\n\nMar 3, 2023\n\n\nFilip Wästberg\n\n\n\n\n\n\n  \n\n\n\n\nMy setup for virtual environments in Python\n\n\n\n\n\n\n\npython\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2023\n\n\nFilip Wästberg\n\n\n\n\n\n\n  \n\n\n\n\nVisualisera valet med swemaps2\n\n\n\n\n\n\n\nvalet\n\n\n\n\n\n\n\n\n\n\n\nSep 20, 2022\n\n\nFilip Wästberg\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGIS och Kartor i R\n\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2021\n\n\nFilip Wästberg\n\n\n\n\n\n\n  \n\n\n\n\nMobilitetstrender från Apple och Google\n\n\n\n\n\n\n\nopen data\n\n\n\n\n\n\n\n\n\n\n\nSep 9, 2020\n\n\nFilip Wästberg\n\n\n\n\n\n\n  \n\n\n\n\nDatabser i R\n\n\n\n\n\n\n\ndatabases\n\n\nsql\n\n\n\n\n\n\n\n\n\n\n\nAug 17, 2020\n\n\nFilip Wästberg\n\n\n\n\n\n\n  \n\n\n\n\nHämta data från Kolada till R\n\n\n\n\n\n\n\nopen data\n\n\nkolada\n\n\n\n\n\n\n\n\n\n\n\nAug 14, 2020\n\n\nFilip Wästberg\n\n\n\n\n\n\n  \n\n\n\n\nHämta data från SCB till R\n\n\n\n\n\n\n\nopen data\n\n\nscb\n\n\n\n\n\n\n\n\n\n\n\nJun 8, 2020\n\n\nFilip Wästberg\n\n\n\n\n\n\n  \n\n\n\n\nAutomatisera PowerPoints med R\n\n\n\n\n\n\n\nopen data\n\n\n\n\n\n\n\n\n\n\n\nMay 8, 2020\n\n\nFilip Wästberg\n\n\n\n\n\n\n  \n\n\n\n\nÖversätt provresultat från Excel till betyg i R\n\n\n\n\n\n\n\nexcel\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2020\n\n\nFilip Wästberg\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Hi!\nMy name is Filip Wästberg and I’m a Data Science Consultant at Solita Sweden. This is my personal blog where I write about data stuff that interest me, mostly in Swedish."
  }
]